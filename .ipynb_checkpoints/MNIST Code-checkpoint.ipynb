{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import scipy.sparse as sp\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "def gaussian_random_tensor(n_components, n_features, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    components = rng.normal(loc=0.0,\n",
    "                            scale=1.0 / np.sqrt(n_components),\n",
    "                            size=(n_components, n_features))\n",
    "    components = components.T\n",
    "    # components = np.sign(components)\n",
    "    return (tf.convert_to_tensor(components, dtype = 'float32'))\n",
    "\n",
    "def _check_density(density, n_features):\n",
    "    \"\"\"Factorize density check according to Li et al.\"\"\"\n",
    "    if density == 'auto':\n",
    "        density = 1 / np.sqrt(n_features)\n",
    "    elif density <= 0 or density > 1:\n",
    "        raise ValueError(\"Expected density in range ]0, 1], got: %r\"\n",
    "                         % density)\n",
    "    return density\n",
    "\n",
    "def sparse_random_tensor(n_components, n_features, density='auto',\n",
    "                         random_state=None):\n",
    " \n",
    "    density = _check_density(density, n_features)\n",
    "    rng = check_random_state(random_state)\n",
    "    if density == 1:\n",
    "        # skip index generation if totally dense\n",
    "        components = rng.binomial(1, 0.5, (n_components, n_features)) * 2 - 1\n",
    "        return 1 / np.sqrt(n_components) * components\n",
    "    else:\n",
    "        indices = []\n",
    "        offset = 0\n",
    "        indptr = [offset]\n",
    "        for i in range(n_components):\n",
    "            # find the indices of the non-zero components for row i\n",
    "            n_nonzero_i = rng.binomial(n_features, density)\n",
    "            indices_i = sample_without_replacement(n_features, n_nonzero_i,\n",
    "                                                   random_state=rng)\n",
    "            indices.append(indices_i)\n",
    "            offset += n_nonzero_i\n",
    "            indptr.append(offset)\n",
    "        indices = np.concatenate(indices)\n",
    "        # Among non zero components the probability of the sign is 50%/50%\n",
    "        data = rng.binomial(1, 0.5, size=np.size(indices)) * 2 - 1\n",
    "        # build the CSR structure by concatenating the rows\n",
    "        components = sp.csr_matrix((data, indices, indptr),\n",
    "                                   shape=(n_components, n_features))\n",
    "        return tf.convert_to_tensor(np.sqrt(1 / density) / np.sqrt(n_components) * components)\n",
    "\n",
    "\n",
    "def project(x, ncomp): #ncomp is the number of dimensions we want to shrink to \n",
    "    features = K.int_shape(x)[1]\n",
    "    Y = gaussian_random_tensor(ncomp, features)\n",
    "    X_new = K.dot(x, Y)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(1, 28, 28...)`\n",
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 302s - loss: 0.2035 - acc: 0.9388   \n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 422s - loss: 0.2359 - acc: 0.9281   \n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 400s - loss: 0.2438 - acc: 0.9256   \n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 356s - loss: 0.2868 - acc: 0.9116   \n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 329s - loss: 0.3285 - acc: 0.8967   \n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 313s - loss: 0.3595 - acc: 0.8854   \n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 297s - loss: 0.4554 - acc: 0.8520   \n"
     ]
    }
   ],
   "source": [
    "dims = [4608, 3456, 2304, 1152, 576, 288, 144]\n",
    "import time\n",
    "accuracy = []\n",
    "size = []\n",
    "times = []\n",
    "epochs = 1\n",
    "for d in dims:\n",
    "    start = time.time()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(1,28,28)))\n",
    "    model.add(Conv2D(32, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    if d != 4608:\n",
    "        model.add(Lambda (lambda x: project(x, d)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, \n",
    "              batch_size=32, nb_epoch=epochs, verbose=1)\n",
    "    \n",
    "    a = model.evaluate(X_test, Y_test, verbose=0)[1]\n",
    "    \n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    accuracy.append(a)\n",
    "    size.append(d)\n",
    "    times.append(t)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Size': size, 'Accuracy': accuracy, 'Runtime': times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Size</th>\n",
       "      <th>time_saved</th>\n",
       "      <th>acc_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9827</td>\n",
       "      <td>328.827820</td>\n",
       "      <td>4608</td>\n",
       "      <td>0.287001</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9777</td>\n",
       "      <td>461.189944</td>\n",
       "      <td>3456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9832</td>\n",
       "      <td>436.124353</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.054350</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9799</td>\n",
       "      <td>389.102376</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.156308</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9772</td>\n",
       "      <td>358.661368</td>\n",
       "      <td>576</td>\n",
       "      <td>0.222313</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy     Runtime  Size  time_saved  acc_lost\n",
       "0    0.9827  328.827820  4608    0.287001    0.0005\n",
       "1    0.9777  461.189944  3456    0.000000    0.0055\n",
       "2    0.9832  436.124353  2304    0.054350    0.0000\n",
       "3    0.9799  389.102376  1152    0.156308    0.0033\n",
       "4    0.9772  358.661368   576    0.222313    0.0060"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_saved'] = (max(df['Runtime']) - df['Runtime']) / max(df['Runtime'])\n",
    "df['acc_lost'] = (max(df['Accuracy']) - df['Accuracy'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
