{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def gaussian_random_tensor(n_components, n_features, sign, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    components = rng.normal(loc=0.0,\n",
    "                            scale=1.0 / np.sqrt(n_components),\n",
    "                            size=(n_components, n_features))\n",
    "    sign_x = lambda t: np.sign(t)\n",
    "    vfunc = np.vectorize(sign_x)\n",
    "    if sign == 1:\n",
    "        vfunc(components)\n",
    "    return (tf.convert_to_tensor(components, dtype = 'float32'))\n",
    "\n",
    "def _check_density(density, n_features):\n",
    "    \"\"\"Factorize density check according to Li et al.\"\"\"\n",
    "    if density == 'auto':\n",
    "        density = 1 / np.sqrt(n_features)\n",
    "    elif density <= 0 or density > 1:\n",
    "        raise ValueError(\"Expected density in range ]0, 1], got: %r\"\n",
    "                         % density)\n",
    "    return density\n",
    "\n",
    "def sparse_random_tensor(n_components, n_features, density='auto',\n",
    "                         random_state=None):\n",
    " \n",
    "    density = _check_density(density, n_features)\n",
    "    rng = check_random_state(random_state)\n",
    "    if density == 1:\n",
    "        # skip index generation if totally dense\n",
    "        components = rng.binomial(1, 0.5, (n_components, n_features)) * 2 - 1\n",
    "        return 1 / np.sqrt(n_components) * components\n",
    "    else:\n",
    "        indices = []\n",
    "        offset = 0\n",
    "        indptr = [offset]\n",
    "        for i in range(n_components):\n",
    "            # find the indices of the non-zero components for row i\n",
    "            n_nonzero_i = rng.binomial(n_features, density)\n",
    "            indices_i = sample_without_replacement(n_features, n_nonzero_i,\n",
    "                                                   random_state=rng)\n",
    "            indices.append(indices_i)\n",
    "            offset += n_nonzero_i\n",
    "            indptr.append(offset)\n",
    "        indices = np.concatenate(indices)\n",
    "        # Among non zero components the probability of the sign is 50%/50%\n",
    "        data = rng.binomial(1, 0.5, size=np.size(indices)) * 2 - 1\n",
    "        # build the CSR structure by concatenating the rows\n",
    "        components = sp.csr_matrix((data, indices, indptr),\n",
    "                                   shape=(n_components, n_features))\n",
    "        return tf.convert_to_tensor(np.sqrt(1 / density) / np.sqrt(n_components) * components)\n",
    "\n",
    "\n",
    "def project(x, ncomp, sign): #ncomp is the number of dimensions we want to shrink to \n",
    "    features = K.int_shape(x)[1] # number of features\n",
    "    Y = gaussian_random_tensor(ncomp, features, sign) # matrix has same # columns as the vector has rows\n",
    "    x = tf.transpose(x) # makes x a column vector\n",
    "    X_new = K.dot(Y, x)\n",
    "    X_new = tf.transpose(X_new)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 445s - loss: 1.4702 - acc: 0.4634 - val_loss: 1.1446 - val_acc: 0.5869\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 424s - loss: 1.0591 - acc: 0.6218 - val_loss: 0.9916 - val_acc: 0.6496\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 424s - loss: 0.8809 - acc: 0.6869 - val_loss: 0.9185 - val_acc: 0.6781\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 420s - loss: 0.7547 - acc: 0.7335 - val_loss: 0.8557 - val_acc: 0.7043\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 418s - loss: 0.6555 - acc: 0.7687 - val_loss: 0.8422 - val_acc: 0.7081\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 418s - loss: 0.5565 - acc: 0.8052 - val_loss: 0.8484 - val_acc: 0.7057\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 419s - loss: 0.4744 - acc: 0.8332 - val_loss: 0.8846 - val_acc: 0.7063\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 418s - loss: 0.4089 - acc: 0.8559 - val_loss: 0.8848 - val_acc: 0.7150\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 418s - loss: 0.3586 - acc: 0.8748 - val_loss: 0.9102 - val_acc: 0.7154\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 418s - loss: 0.3154 - acc: 0.8915 - val_loss: 0.9838 - val_acc: 0.7107\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 342s - loss: 1.4967 - acc: 0.4588 - val_loss: 1.1944 - val_acc: 0.5740\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 332s - loss: 1.1077 - acc: 0.6049 - val_loss: 1.0188 - val_acc: 0.6286\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 334s - loss: 0.9379 - acc: 0.6691 - val_loss: 0.9479 - val_acc: 0.6690\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 333s - loss: 0.8231 - acc: 0.7095 - val_loss: 0.8961 - val_acc: 0.6845\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 333s - loss: 0.7283 - acc: 0.7437 - val_loss: 0.8905 - val_acc: 0.6963\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 333s - loss: 0.6468 - acc: 0.7739 - val_loss: 0.8804 - val_acc: 0.6956\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 333s - loss: 0.5701 - acc: 0.7972 - val_loss: 0.9027 - val_acc: 0.7093\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 333s - loss: 0.5219 - acc: 0.8148 - val_loss: 0.9063 - val_acc: 0.7107\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 336s - loss: 0.4636 - acc: 0.8353 - val_loss: 0.9144 - val_acc: 0.7141\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 332s - loss: 0.4155 - acc: 0.8513 - val_loss: 0.9652 - val_acc: 0.6990\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 302s - loss: 1.4992 - acc: 0.4586 - val_loss: 1.2700 - val_acc: 0.5460\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 292s - loss: 1.1710 - acc: 0.5822 - val_loss: 1.1247 - val_acc: 0.6018\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 292s - loss: 1.0282 - acc: 0.6344 - val_loss: 1.0224 - val_acc: 0.6355\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 292s - loss: 0.9214 - acc: 0.6703 - val_loss: 0.9347 - val_acc: 0.6694\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 292s - loss: 0.8317 - acc: 0.7056 - val_loss: 0.9923 - val_acc: 0.6553\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 292s - loss: 0.7549 - acc: 0.7314 - val_loss: 0.9426 - val_acc: 0.6801\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 292s - loss: 0.6889 - acc: 0.7551 - val_loss: 0.9219 - val_acc: 0.6888\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 292s - loss: 0.6291 - acc: 0.7772 - val_loss: 0.9818 - val_acc: 0.6662\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 292s - loss: 0.5778 - acc: 0.7946 - val_loss: 0.9462 - val_acc: 0.6864\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 291s - loss: 0.5306 - acc: 0.8118 - val_loss: 1.0045 - val_acc: 0.6820\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 288s - loss: 1.5686 - acc: 0.4364 - val_loss: 1.3498 - val_acc: 0.5058\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 282s - loss: 1.2507 - acc: 0.5545 - val_loss: 1.1588 - val_acc: 0.5921\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 282s - loss: 1.1084 - acc: 0.6051 - val_loss: 1.0554 - val_acc: 0.6270\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 283s - loss: 1.0185 - acc: 0.6399 - val_loss: 1.0999 - val_acc: 0.6103\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 282s - loss: 0.9542 - acc: 0.6618 - val_loss: 0.9912 - val_acc: 0.6499\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 282s - loss: 0.8982 - acc: 0.6812 - val_loss: 0.9991 - val_acc: 0.6498\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 282s - loss: 0.8524 - acc: 0.6983 - val_loss: 0.9717 - val_acc: 0.6617\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 282s - loss: 0.8107 - acc: 0.7122 - val_loss: 0.9549 - val_acc: 0.6695\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 282s - loss: 0.7777 - acc: 0.7258 - val_loss: 0.9558 - val_acc: 0.6737\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 283s - loss: 0.7468 - acc: 0.7355 - val_loss: 0.9787 - val_acc: 0.6705\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 286s - loss: 1.6371 - acc: 0.4043 - val_loss: 1.3975 - val_acc: 0.4960\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 279s - loss: 1.3424 - acc: 0.5186 - val_loss: 1.2716 - val_acc: 0.5387\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 280s - loss: 1.2346 - acc: 0.5581 - val_loss: 1.1738 - val_acc: 0.5857\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 280s - loss: 1.1615 - acc: 0.5850 - val_loss: 1.1397 - val_acc: 0.5986\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 280s - loss: 1.1104 - acc: 0.6061 - val_loss: 1.0945 - val_acc: 0.6130\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 281s - loss: 1.0601 - acc: 0.6251 - val_loss: 1.1019 - val_acc: 0.6099\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 280s - loss: 1.0211 - acc: 0.6347 - val_loss: 1.0626 - val_acc: 0.6185\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 280s - loss: 0.9963 - acc: 0.6440 - val_loss: 1.0332 - val_acc: 0.6382\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 280s - loss: 0.9638 - acc: 0.6577 - val_loss: 1.0233 - val_acc: 0.6383\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 281s - loss: 0.9495 - acc: 0.6632 - val_loss: 1.0067 - val_acc: 0.6462\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 286s - loss: 1.6576 - acc: 0.3879 - val_loss: 1.4317 - val_acc: 0.4766\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.4019 - acc: 0.4896 - val_loss: 1.3316 - val_acc: 0.5134\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 279s - loss: 1.3194 - acc: 0.5214 - val_loss: 1.2736 - val_acc: 0.5447\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.2639 - acc: 0.5443 - val_loss: 1.2375 - val_acc: 0.5455\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.2187 - acc: 0.5624 - val_loss: 1.2383 - val_acc: 0.5580\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.1869 - acc: 0.5742 - val_loss: 1.1818 - val_acc: 0.5753\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.1615 - acc: 0.5852 - val_loss: 1.1439 - val_acc: 0.5898\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.1375 - acc: 0.5926 - val_loss: 1.1086 - val_acc: 0.5994\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.1204 - acc: 0.5996 - val_loss: 1.1470 - val_acc: 0.5874\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 278s - loss: 1.1040 - acc: 0.6059 - val_loss: 1.0942 - val_acc: 0.6103\n"
     ]
    }
   ],
   "source": [
    "dims = [2048, 1024, 512, 256, 128, 64]\n",
    "import time\n",
    "accuracy = []\n",
    "size = []\n",
    "times = []\n",
    "epochs = 10\n",
    "\n",
    "for d in dims:\n",
    "    start = time.time()\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    if d != 2048:\n",
    "        model.add(Lambda (lambda x: project(x, d, 0)))\n",
    "        \n",
    "    model.add(Dense(d, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "\n",
    "    model.add(Dense(50, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
    "    a = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    \n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    accuracy.append(a)\n",
    "    size.append(d)\n",
    "    times.append(t)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Size': size, 'Accuracy': accuracy, 'Runtime': times})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Size</th>\n",
       "      <th>time_saved</th>\n",
       "      <th>acc_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7107</td>\n",
       "      <td>4258.122126</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6990</td>\n",
       "      <td>3376.166322</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.207123</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6820</td>\n",
       "      <td>2963.589998</td>\n",
       "      <td>512</td>\n",
       "      <td>0.304015</td>\n",
       "      <td>0.0287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6705</td>\n",
       "      <td>2861.366039</td>\n",
       "      <td>256</td>\n",
       "      <td>0.328022</td>\n",
       "      <td>0.0402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6462</td>\n",
       "      <td>2840.649288</td>\n",
       "      <td>128</td>\n",
       "      <td>0.332887</td>\n",
       "      <td>0.0645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6103</td>\n",
       "      <td>2821.885366</td>\n",
       "      <td>64</td>\n",
       "      <td>0.337293</td>\n",
       "      <td>0.1004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy      Runtime  Size  time_saved  acc_lost\n",
       "0    0.7107  4258.122126  2048    0.000000    0.0000\n",
       "1    0.6990  3376.166322  1024    0.207123    0.0117\n",
       "2    0.6820  2963.589998   512    0.304015    0.0287\n",
       "3    0.6705  2861.366039   256    0.328022    0.0402\n",
       "4    0.6462  2840.649288   128    0.332887    0.0645\n",
       "5    0.6103  2821.885366    64    0.337293    0.1004"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_saved'] = (max(df['Runtime']) - df['Runtime']) / max(df['Runtime'])\n",
    "df['acc_lost'] = (max(df['Accuracy']) - df['Accuracy'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Cifar_gaussian_no_sign.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_165 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_165 (MaxPoolin (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 32, 16, 16)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_166 (MaxPoolin (None, 32, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "lambda_71 (Lambda)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 18,064\n",
      "Trainable params: 18,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x20f7da5c0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_156')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer('dense_156').output)\n",
    "intermediate_output = intermediate_layer_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "t_sne = TSNE(n_components=2, random_state=0)\n",
    "ts = t_sne.fit_transform(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "c of shape (10000, 10, 3) not acceptable as a color sequence for x with size 10000, y with size 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4049\u001b[0m                 \u001b[0;31m# must be acceptable as PathCollection facecolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4050\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4051\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Test dimensionality to reject single floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Return a tuple to prevent the cached value from being modified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: array([[ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.6832,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ],\n       [ 0.86  ,  0.3712,  0.34  ]])",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-4fecada1fecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-4fecada1fecd>\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, colors)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'equal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n\u001b[0;32m---> 11\u001b[0;31m                     c=palette[colors.astype(np.int)])\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4053\u001b[0m                 msg = (\"c of shape {0} not acceptable as a color sequence \"\n\u001b[1;32m   4054\u001b[0m                        \"for x with size {1}, y with size {2}\")\n\u001b[0;32m-> 4055\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4056\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4057\u001b[0m             \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# use cmap, norm after collection is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: c of shape (10000, 10, 3) not acceptable as a color sequence for x with size 10000, y with size 10000"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHWCAYAAACv91olAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d3836d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def scatter(x, colors):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(10):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts\n",
    "\n",
    "scatter(ts, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
