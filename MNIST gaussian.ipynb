{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import scipy.sparse as sp\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "def gaussian_random_tensor(n_components, n_features, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    components = rng.normal(loc=0.0,\n",
    "                            scale=1.0 / np.sqrt(n_components),\n",
    "                            size=(n_components, n_features))\n",
    "    components = components.T\n",
    "    # components = np.sign(components)\n",
    "    return (tf.convert_to_tensor(components, dtype = 'float32'))\n",
    "\n",
    "def _check_density(density, n_features):\n",
    "    \"\"\"Factorize density check according to Li et al.\"\"\"\n",
    "    if density == 'auto':\n",
    "        density = 1 / np.sqrt(n_features)\n",
    "    elif density <= 0 or density > 1:\n",
    "        raise ValueError(\"Expected density in range ]0, 1], got: %r\"\n",
    "                         % density)\n",
    "    return density\n",
    "\n",
    "def sparse_random_tensor(n_components, n_features, density='auto',\n",
    "                         random_state=None):\n",
    " \n",
    "    density = _check_density(density, n_features)\n",
    "    rng = check_random_state(random_state)\n",
    "    if density == 1:\n",
    "        # skip index generation if totally dense\n",
    "        components = rng.binomial(1, 0.5, (n_components, n_features)) * 2 - 1\n",
    "        return 1 / np.sqrt(n_components) * components\n",
    "    else:\n",
    "        indices = []\n",
    "        offset = 0\n",
    "        indptr = [offset]\n",
    "        for i in range(n_components):\n",
    "            # find the indices of the non-zero components for row i\n",
    "            n_nonzero_i = rng.binomial(n_features, density)\n",
    "            indices_i = sample_without_replacement(n_features, n_nonzero_i,\n",
    "                                                   random_state=rng)\n",
    "            indices.append(indices_i)\n",
    "            offset += n_nonzero_i\n",
    "            indptr.append(offset)\n",
    "        indices = np.concatenate(indices)\n",
    "        # Among non zero components the probability of the sign is 50%/50%\n",
    "        data = rng.binomial(1, 0.5, size=np.size(indices)) * 2 - 1\n",
    "        # build the CSR structure by concatenating the rows\n",
    "        components = sp.csr_matrix((data, indices, indptr),\n",
    "                                   shape=(n_components, n_features))\n",
    "        return tf.convert_to_tensor(np.sqrt(1 / density) / np.sqrt(n_components) * components)\n",
    "\n",
    "\n",
    "def project(x, ncomp): #ncomp is the number of dimensions we want to shrink to \n",
    "    features = K.int_shape(x)[1]\n",
    "    Y = gaussian_random_tensor(ncomp, features)\n",
    "    X_new = K.dot(x, Y)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(1, 28, 28...)`\n",
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 302s - loss: 0.2134 - acc: 0.9356   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 302s - loss: 0.0882 - acc: 0.9735   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 307s - loss: 0.0697 - acc: 0.9794   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 301s - loss: 0.0587 - acc: 0.9819   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 295s - loss: 0.0509 - acc: 0.9846   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 294s - loss: 0.0443 - acc: 0.9863   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 294s - loss: 0.0413 - acc: 0.9876   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 294s - loss: 0.0361 - acc: 0.9890   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 298s - loss: 0.0326 - acc: 0.9895   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 294s - loss: 0.0304 - acc: 0.9907   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 424s - loss: 0.2442 - acc: 0.9226   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 423s - loss: 0.1090 - acc: 0.9678   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 427s - loss: 0.0870 - acc: 0.9737   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 425s - loss: 0.0754 - acc: 0.9779   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 423s - loss: 0.0664 - acc: 0.9791   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 427s - loss: 0.0573 - acc: 0.9821   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 425s - loss: 0.0553 - acc: 0.9836   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 423s - loss: 0.0506 - acc: 0.9842   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 425s - loss: 0.0470 - acc: 0.9853   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 424s - loss: 0.0453 - acc: 0.9852   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 382s - loss: 0.2400 - acc: 0.9268   - ETA: 3s - loss: 0.\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 382s - loss: 0.1063 - acc: 0.9680   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 385s - loss: 0.0857 - acc: 0.9737   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 381s - loss: 0.0731 - acc: 0.9781   - ETA: 8s - loss: 0.0 - ETA: 4s - loss: 0.0726 - acc:  - ETA: 3s - loss: 0.0726 - acc: 0.97 - ETA: 3s - loss: 0.07\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 381s - loss: 0.0660 - acc: 0.9798   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 382s - loss: 0.0592 - acc: 0.9817   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 381s - loss: 0.0541 - acc: 0.9829   - ETA: 2s - loss: 0.0540 -\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 381s - loss: 0.0509 - acc: 0.9843   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 381s - loss: 0.0476 - acc: 0.9849   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 386s - loss: 0.0432 - acc: 0.9856   - ETA: 5s - \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 345s - loss: 0.2816 - acc: 0.9133   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 344s - loss: 0.1170 - acc: 0.9637   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 344s - loss: 0.0945 - acc: 0.9722   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 344s - loss: 0.0836 - acc: 0.9749   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 344s - loss: 0.0756 - acc: 0.9770   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 344s - loss: 0.0667 - acc: 0.9798   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 344s - loss: 0.0637 - acc: 0.9799   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 349s - loss: 0.0614 - acc: 0.9810   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 345s - loss: 0.0559 - acc: 0.9827   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 344s - loss: 0.0523 - acc: 0.9833   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.3008 - acc: 0.9058   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 317s - loss: 0.1287 - acc: 0.9606   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.1027 - acc: 0.9683   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 317s - loss: 0.0916 - acc: 0.9725   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.0836 - acc: 0.9749   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.0758 - acc: 0.9765   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 323s - loss: 0.0709 - acc: 0.9781   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.0668 - acc: 0.9793   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.0651 - acc: 0.9799   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.0643 - acc: 0.9806   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 305s - loss: 0.3883 - acc: 0.8772   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 304s - loss: 0.1591 - acc: 0.9520   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 305s - loss: 0.1302 - acc: 0.9600   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 304s - loss: 0.1135 - acc: 0.9655   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 305s - loss: 0.1047 - acc: 0.9681   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 308s - loss: 0.0945 - acc: 0.9708   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 304s - loss: 0.0934 - acc: 0.9718   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 304s - loss: 0.0884 - acc: 0.9726   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 305s - loss: 0.0842 - acc: 0.9740   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 305s - loss: 0.0795 - acc: 0.9758   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 288s - loss: 0.4416 - acc: 0.8582   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 287s - loss: 0.2105 - acc: 0.9350   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 287s - loss: 0.1725 - acc: 0.9481   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 290s - loss: 0.1551 - acc: 0.9531   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 287s - loss: 0.1435 - acc: 0.9569   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 290s - loss: 0.1329 - acc: 0.9594   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 288s - loss: 0.1244 - acc: 0.9613   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 288s - loss: 0.1186 - acc: 0.9636   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 289s - loss: 0.1170 - acc: 0.9639   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 287s - loss: 0.1107 - acc: 0.9664   \n"
     ]
    }
   ],
   "source": [
    "dims = [4608, 3456, 2304, 1152, 576, 288, 144]\n",
    "import time\n",
    "accuracy = []\n",
    "size = []\n",
    "times = []\n",
    "epochs = 10\n",
    "for d in dims:\n",
    "    start = time.time()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(1,28,28)))\n",
    "    model.add(Conv2D(32, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    if d != 4608:\n",
    "        model.add(Lambda (lambda x: project(x, d)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, \n",
    "              batch_size=32, nb_epoch=epochs, verbose=1)\n",
    "    \n",
    "    a = model.evaluate(X_test, Y_test, verbose=0)[1]\n",
    "    \n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    accuracy.append(a)\n",
    "    size.append(d)\n",
    "    times.append(t)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Size': size, 'Accuracy': accuracy, 'Runtime': times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Size</th>\n",
       "      <th>time_saved</th>\n",
       "      <th>acc_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9915</td>\n",
       "      <td>3013.676759</td>\n",
       "      <td>4608</td>\n",
       "      <td>0.297563</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9908</td>\n",
       "      <td>4290.314091</td>\n",
       "      <td>3456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9909</td>\n",
       "      <td>3862.926646</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.099617</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9901</td>\n",
       "      <td>3484.538885</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.187813</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9899</td>\n",
       "      <td>3217.020336</td>\n",
       "      <td>576</td>\n",
       "      <td>0.250167</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy      Runtime  Size  time_saved  acc_lost\n",
       "0    0.9915  3013.676759  4608    0.297563    0.0000\n",
       "1    0.9908  4290.314091  3456    0.000000    0.0007\n",
       "2    0.9909  3862.926646  2304    0.099617    0.0006\n",
       "3    0.9901  3484.538885  1152    0.187813    0.0014\n",
       "4    0.9899  3217.020336   576    0.250167    0.0016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_saved'] = (max(df['Runtime']) - df['Runtime']) / max(df['Runtime'])\n",
    "df['acc_lost'] = (max(df['Accuracy']) - df['Accuracy'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
