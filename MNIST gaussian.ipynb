{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jackholder/anaconda2/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import scipy.sparse as sp\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "def gaussian_random_tensor(n_components, n_features, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    components = rng.normal(loc=0.0,\n",
    "                            scale=1.0 / np.sqrt(n_components),\n",
    "                            size=(n_components, n_features))\n",
    "    components = components.T\n",
    "    # components = np.sign(components)\n",
    "    return (tf.convert_to_tensor(components, dtype = 'float32'))\n",
    "\n",
    "def _check_density(density, n_features):\n",
    "    \"\"\"Factorize density check according to Li et al.\"\"\"\n",
    "    if density == 'auto':\n",
    "        density = 1 / np.sqrt(n_features)\n",
    "    elif density <= 0 or density > 1:\n",
    "        raise ValueError(\"Expected density in range ]0, 1], got: %r\"\n",
    "                         % density)\n",
    "    return density\n",
    "\n",
    "def sparse_random_tensor(n_components, n_features, density='auto',\n",
    "                         random_state=None):\n",
    " \n",
    "    density = _check_density(density, n_features)\n",
    "    rng = check_random_state(random_state)\n",
    "    if density == 1:\n",
    "        # skip index generation if totally dense\n",
    "        components = rng.binomial(1, 0.5, (n_components, n_features)) * 2 - 1\n",
    "        return 1 / np.sqrt(n_components) * components\n",
    "    else:\n",
    "        indices = []\n",
    "        offset = 0\n",
    "        indptr = [offset]\n",
    "        for i in range(n_components):\n",
    "            # find the indices of the non-zero components for row i\n",
    "            n_nonzero_i = rng.binomial(n_features, density)\n",
    "            indices_i = sample_without_replacement(n_features, n_nonzero_i,\n",
    "                                                   random_state=rng)\n",
    "            indices.append(indices_i)\n",
    "            offset += n_nonzero_i\n",
    "            indptr.append(offset)\n",
    "        indices = np.concatenate(indices)\n",
    "        # Among non zero components the probability of the sign is 50%/50%\n",
    "        data = rng.binomial(1, 0.5, size=np.size(indices)) * 2 - 1\n",
    "        # build the CSR structure by concatenating the rows\n",
    "        components = sp.csr_matrix((data, indices, indptr),\n",
    "                                   shape=(n_components, n_features))\n",
    "        return tf.convert_to_tensor(np.sqrt(1 / density) / np.sqrt(n_components) * components)\n",
    "\n",
    "\n",
    "def project(x, ncomp): #ncomp is the number of dimensions we want to shrink to \n",
    "    features = K.int_shape(x)[1]\n",
    "    Y = gaussian_random_tensor(ncomp, features)\n",
    "    X_new = K.dot(x, Y)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 518s - loss: 0.1197 - acc: 0.9625   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 500s - loss: 0.0455 - acc: 0.9862   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 499s - loss: 0.0314 - acc: 0.9903   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 497s - loss: 0.0239 - acc: 0.9928   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 497s - loss: 0.0213 - acc: 0.9931   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 504s - loss: 0.0156 - acc: 0.9951   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 500s - loss: 0.0155 - acc: 0.9952   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 498s - loss: 0.0126 - acc: 0.9963   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 497s - loss: 0.0115 - acc: 0.9967   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 497s - loss: 0.0123 - acc: 0.9963   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 687s - loss: 0.1157 - acc: 0.9636   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 678s - loss: 0.0487 - acc: 0.9848   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 675s - loss: 0.0367 - acc: 0.9883   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 674s - loss: 0.0272 - acc: 0.9915   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 680s - loss: 0.0243 - acc: 0.9923   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 678s - loss: 0.0215 - acc: 0.9934   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 675s - loss: 0.0188 - acc: 0.9943   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 676s - loss: 0.0172 - acc: 0.9951   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 675s - loss: 0.0176 - acc: 0.9948   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 684s - loss: 0.0138 - acc: 0.9961   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 457s - loss: 0.1168 - acc: 0.9632   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 453s - loss: 0.0489 - acc: 0.9849   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 453s - loss: 0.0354 - acc: 0.9887   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 453s - loss: 0.0278 - acc: 0.9912   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 454s - loss: 0.0236 - acc: 0.9925   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 462s - loss: 0.0201 - acc: 0.9934   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 455s - loss: 0.0187 - acc: 0.9939   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 455s - loss: 0.0150 - acc: 0.9951   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 454s - loss: 0.0157 - acc: 0.9952   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 455s - loss: 0.0135 - acc: 0.9959   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 321s - loss: 0.1279 - acc: 0.9611   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 324s - loss: 0.0483 - acc: 0.9850   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 320s - loss: 0.0349 - acc: 0.9894   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 319s - loss: 0.0276 - acc: 0.9915   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.0223 - acc: 0.9927   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 317s - loss: 0.0190 - acc: 0.9938   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 318s - loss: 0.0165 - acc: 0.9949   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 317s - loss: 0.0149 - acc: 0.9952   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 317s - loss: 0.0142 - acc: 0.9956   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 319s - loss: 0.0125 - acc: 0.9960   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 289s - loss: 0.1370 - acc: 0.9578   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 282s - loss: 0.0512 - acc: 0.9836   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 281s - loss: 0.0368 - acc: 0.9879   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 281s - loss: 0.0292 - acc: 0.9907   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 281s - loss: 0.0253 - acc: 0.9916   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 280s - loss: 0.0221 - acc: 0.9926   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 281s - loss: 0.0174 - acc: 0.9943   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 279s - loss: 0.0170 - acc: 0.9943   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 279s - loss: 0.0148 - acc: 0.9954   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 281s - loss: 0.0137 - acc: 0.9954   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 278s - loss: 0.1661 - acc: 0.9486   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 274s - loss: 0.0564 - acc: 0.9819   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 275s - loss: 0.0451 - acc: 0.9861   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 271s - loss: 0.0352 - acc: 0.9888   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 271s - loss: 0.0304 - acc: 0.9900   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 271s - loss: 0.0251 - acc: 0.9917   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 271s - loss: 0.0214 - acc: 0.9928   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 269s - loss: 0.0210 - acc: 0.9929   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 270s - loss: 0.0182 - acc: 0.9936   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 271s - loss: 0.0159 - acc: 0.9946   \n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 268s - loss: 0.1927 - acc: 0.9405   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 273s - loss: 0.0673 - acc: 0.9792   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 268s - loss: 0.0512 - acc: 0.9840   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 267s - loss: 0.0400 - acc: 0.9873   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 267s - loss: 0.0360 - acc: 0.9883   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 267s - loss: 0.0317 - acc: 0.9898   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 266s - loss: 0.0280 - acc: 0.9907   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 265s - loss: 0.0244 - acc: 0.9915   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 265s - loss: 0.0222 - acc: 0.9927   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 267s - loss: 0.0206 - acc: 0.9932   \n"
     ]
    }
   ],
   "source": [
    "dims = [4608, 3456, 2304, 1152, 576, 288, 144]\n",
    "import time\n",
    "accuracy = []\n",
    "size = []\n",
    "times = []\n",
    "epochs = 10\n",
    "for d in dims:\n",
    "    start = time.time()\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(1,28,28), kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    if d != 4608:\n",
    "        model.add(Lambda (lambda x: project(x, d)))\n",
    "    model.add(Dense(d, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    h = model.fit(X_train, Y_train, batch_size=32, epochs=epochs, verbose=1)\n",
    "    \n",
    "    a = model.evaluate(X_test, Y_test, verbose=0)[1]\n",
    "    \n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    accuracy.append(a)\n",
    "    size.append(d)\n",
    "    times.append(t)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Size': size, 'Accuracy': accuracy, 'Runtime': times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Size</th>\n",
       "      <th>time_saved</th>\n",
       "      <th>acc_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9891</td>\n",
       "      <td>5043.912917</td>\n",
       "      <td>4608</td>\n",
       "      <td>0.260923</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9910</td>\n",
       "      <td>6824.607547</td>\n",
       "      <td>3456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9867</td>\n",
       "      <td>4590.439886</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.327369</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9884</td>\n",
       "      <td>3224.516772</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.527516</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9893</td>\n",
       "      <td>2847.549422</td>\n",
       "      <td>576</td>\n",
       "      <td>0.582753</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy      Runtime  Size  time_saved  acc_lost\n",
       "0    0.9891  5043.912917  4608    0.260923    0.0019\n",
       "1    0.9910  6824.607547  3456    0.000000    0.0000\n",
       "2    0.9867  4590.439886  2304    0.327369    0.0043\n",
       "3    0.9884  3224.516772  1152    0.527516    0.0026\n",
       "4    0.9893  2847.549422   576    0.582753    0.0017"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_saved'] = (max(df['Runtime']) - df['Runtime']) / max(df['Runtime'])\n",
    "df['acc_lost'] = (max(df['Accuracy']) - df['Accuracy'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
