{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.linalg import circulant\n",
    "from scipy.linalg import hadamard\n",
    "from scipy.linalg import toeplitz\n",
    "import random\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "def gaussian_random_tensor(n_components, n_features, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    components = rng.normal(loc=0.0,\n",
    "                            scale=1.0 / np.sqrt(n_components),\n",
    "                            size=(n_components, n_features))\n",
    "    return (tf.convert_to_tensor(components, dtype = 'float32'))\n",
    "\n",
    "def hadamard_mat(n_components, n_features):\n",
    "    had = hadamard(n_features, dtype=complex)\n",
    "    had = had[np.random.choice(had.shape[0], n_components, replace=False)]\n",
    "    return had\n",
    "\n",
    "def diagonal_mat(n_components, n_features):\n",
    "    components = np.random.rand(n_features)\n",
    "    components = np.diag(components)\n",
    "    components = components[0:n_components]\n",
    "    components = np.sign(components)\n",
    "    return components\n",
    "\n",
    "def circulant_random_tensor(n_components, n_features):\n",
    "    components = np.random.normal(0, 1, (1, n_features))\n",
    "    components = circulant(components)\n",
    "    diag1 = diagonal_mat(n_features, n_features)\n",
    "    # diag2 = diagonal_mat(n_features, n_features)\n",
    "    # had = hadamard_mat(n_features, n_features)\n",
    "    # HD = np.dot(had, diag1)\n",
    "    # DHD = np.dot(diag2, HD)\n",
    "    # components = np.dot(components, DHD) # Extended Ψ-regular hashing\n",
    "    components = np.dot(components, diag1) # Short Ψ-regular hashing \n",
    "    components = components[np.random.choice(components.shape[0], n_components, replace=False)]\n",
    "    return (tf.convert_to_tensor(components, dtype = 'float32'))\n",
    "\n",
    "def toeplitz_random_tensor(n_components, n_features):\n",
    "    components = np.random.normal(0, 1, (1, n_features))\n",
    "    components = toeplitz(components)\n",
    "    diag1 = diagonal_mat(n_features, n_features)\n",
    "    # diag2 = diagonal_mat(n_features, n_features)\n",
    "    # had = hadamard_mat(n_features, n_features)\n",
    "    # HD = np.dot(had, diag1)\n",
    "    # DHD = np.dot(diag2, HD)\n",
    "    # components = np.dot(components, DHD) # Extended Ψ-regular hashing\n",
    "    components = np.dot(components, diag1) # Short Ψ-regular hashing \n",
    "    components = components[np.random.choice(components.shape[0], n_components, replace=False)]\n",
    "    return (tf.convert_to_tensor(components, dtype = 'float32'))\n",
    "\n",
    "def kac_matrix(dim, n):\n",
    "    maxiter = n * math.log(n)\n",
    "    for k in tqdm.tqdm(range(1, int(maxiter))):\n",
    "        i = random.randint(0, n-1)\n",
    "        j = random.randint(0, n-1)\n",
    "        while j == i:\n",
    "            j = random.randint(0, n-1)\n",
    "        theta = np.random.uniform(0, 2*math.pi)\n",
    "        B_new = np.identity(n)\n",
    "        B_new[i, i] = math.sin(theta)\n",
    "        B_new[i, j] = math.cos(theta)\n",
    "        B_new[j, i] = -math.cos(theta)\n",
    "        B_new[j, j] = math.sin(theta)\n",
    "        if k == 1:\n",
    "            M = B_new\n",
    "        else:\n",
    "            M = np.dot(M, B_new)\n",
    "    M = M[np.random.choice(M.shape[0], dim, replace=False)]\n",
    "    return (tf.convert_to_tensor(M, dtype = 'float32'))\n",
    "          \n",
    "def project(x, Y):  \n",
    "    features = K.int_shape(x)[1] \n",
    "    x = tf.transpose(x)\n",
    "    # Y = tf.sign(Y) # use this if it is doing the sign BEFORE (we think right, he supposedly said wrong)\n",
    "    X_new = K.dot(Y, x)\n",
    "    X_new = tf.transpose(X_new)\n",
    "    X_new = tf.sign(X_new) # use this if it is doing the sign AFTER (we think wrong, he says right)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 260s - loss: 0.2406 - acc: 0.9250 - val_loss: 0.1541 - val_acc: 0.9528\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 262s - loss: 0.1203 - acc: 0.9620 - val_loss: 0.1156 - val_acc: 0.9629\n",
      "Epoch 3/10\n",
      "58848/60000 [============================>.] - ETA: 4s - loss: 0.0935 - acc: 0.9697"
     ]
    }
   ],
   "source": [
    "dims = [784, 392, 196, 98, 49]\n",
    "import time\n",
    "accuracy = []\n",
    "size = []\n",
    "times = []\n",
    "epochs = 10\n",
    "\n",
    "for d in dims:\n",
    "    start = time.time()\n",
    "    \n",
    "    if d != 1568:\n",
    "        # Y = gaussian_random_tensor(d, 1568) \n",
    "        # Y = kac_matrix(d, 1568) \n",
    "        Y = circulant_random_tensor(d, 1568) \n",
    "        # Y = toeplitz_random_tensor(d, 1568)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(1,28,28), kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    if d != 1568:\n",
    "        model.add(Lambda (lambda x: project(x, Y)))\n",
    "        \n",
    "    model.add(Dense(50, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    h = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=epochs, verbose=1)\n",
    "    \n",
    "    a = model.evaluate(X_test, Y_test, verbose=0)[1]\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    accuracy.append(a)\n",
    "    size.append(d)\n",
    "    times.append(t)\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Size': size, 'Accuracy': accuracy, 'Runtime': times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Size</th>\n",
       "      <th>time_saved</th>\n",
       "      <th>acc_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9625</td>\n",
       "      <td>3626.306907</td>\n",
       "      <td>784</td>\n",
       "      <td>0.144657</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9533</td>\n",
       "      <td>3443.917690</td>\n",
       "      <td>392</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9133</td>\n",
       "      <td>3395.172000</td>\n",
       "      <td>196</td>\n",
       "      <td>0.199175</td>\n",
       "      <td>0.0492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8780</td>\n",
       "      <td>4051.382086</td>\n",
       "      <td>98</td>\n",
       "      <td>0.044394</td>\n",
       "      <td>0.0845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7474</td>\n",
       "      <td>4239.594226</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy      Runtime  Size  time_saved  acc_lost\n",
       "0    0.9625  3626.306907   784    0.144657    0.0000\n",
       "1    0.9533  3443.917690   392    0.187678    0.0092\n",
       "2    0.9133  3395.172000   196    0.199175    0.0492\n",
       "3    0.8780  4051.382086    98    0.044394    0.0845\n",
       "4    0.7474  4239.594226    49    0.000000    0.2151"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_saved'] = (max(df['Runtime']) - df['Runtime']) / max(df['Runtime'])\n",
    "df['acc_lost'] = (max(df['Accuracy']) - df['Accuracy'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Mnist_kac_nosign.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
